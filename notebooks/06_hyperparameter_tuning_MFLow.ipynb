{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89cf7200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.4\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "print(xgb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "260096cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/basil-owiti/ML_RegPipeline_Endtoend/.venv/bin/python\n",
      "3.0.4\n",
      "/home/basil-owiti/ML_RegPipeline_Endtoend/.venv/lib/python3.11/site-packages/xgboost/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import sys, xgboost as xgb\n",
    "print(sys.executable)        # should point to .../.venv/bin/python\n",
    "print(xgb.__version__)       # should print 3.0.4\n",
    "print(xgb.__file__)          # should live under .../.venv/..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "478bf394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# 1. Imports\n",
    "# ==============================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import optuna\n",
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "from here import here\n",
    "import os\n",
    "\n",
    "\n",
    "home_dir = os.path.dirname(here())\n",
    "data_dir = os.path.join(home_dir, \"data\")\n",
    "data_dir\n",
    "\n",
    "plot_dir = os.path.join(home_dir, \"plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0bc804c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (576815, 39)\n",
      "Eval shape: (148448, 39)\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# 2. Load processed datasets\n",
    "# ==============================================\n",
    "train_df = pd.read_csv(os.path.join(data_dir, \"processed\", \"feature_engineered_train.csv\"))\n",
    "eval_df  = pd.read_csv(os.path.join(data_dir, \"processed\", \"feature_engineered_eval.csv\"))\n",
    "\n",
    "\n",
    "# Define target + features\n",
    "target = \"price\"\n",
    "X_train, y_train = train_df.drop(columns=[target]), train_df[target]\n",
    "X_eval, y_eval   = eval_df.drop(columns=[target]), eval_df[target]\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Eval shape:\", X_eval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadb78cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# 3. Define Optuna objective function with MLflow\n",
    "# ==============================================\n",
    "def objective(trial):\n",
    "    \"\"\"pass possible parameter values to optuna for experimentation\"\"\"\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 1000),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 5.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 10.0, log=True),\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1,\n",
    "        \"tree_method\": \"hist\",\n",
    "    }\n",
    "    # track runs with mlflow\n",
    "    with mlflow.start_run(nested=True):\n",
    "        model = XGBRegressor(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_eval)\n",
    "        rmse = float(np.sqrt(mean_squared_error(y_eval, y_pred)))\n",
    "        mae = float(mean_absolute_error(y_eval, y_pred))\n",
    "        r2 = float(r2_score(y_eval, y_pred))\n",
    "\n",
    "        # Log hyperparameters + metrics\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metrics({\"rmse\": rmse, \"mae\": mae, \"r2\": r2})\n",
    "\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ed4b5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/basil-owiti/ML_RegPipeline_Endtoend/.venv/lib/python3.11/site-packages/mlflow/tracking/_tracking_service/utils.py:178: FutureWarning: The filesystem tracking backend (e.g., './mlruns') will be deprecated in February 2026. Consider transitioning to a database backend (e.g., 'sqlite:///mlflow.db') to take advantage of the latest MLflow features. See https://github.com/mlflow/mlflow/issues/18534 for more details and migration guidance. For migrating existing data, https://github.com/mlflow/mlflow-export-import can be used.\n",
      "  return FileStore(store_uri, store_uri)\n",
      "2025/12/27 18:30:06 INFO mlflow.tracking.fluent: Experiment with name 'xgboost_optuna_housing' does not exist. Creating a new experiment.\n",
      "[I 2025-12-27 18:30:06,153] A new study created in memory with name: no-name-ebc675df-042f-44fc-8796-e52a180d0494\n",
      "[I 2025-12-27 18:32:29,639] Trial 0 finished with value: 68119.8893549254 and parameters: {'n_estimators': 236, 'max_depth': 8, 'learning_rate': 0.057427200730873144, 'subsample': 0.9665654781256106, 'colsample_bytree': 0.6357966360557227, 'min_child_weight': 4, 'gamma': 3.393559749900545, 'reg_alpha': 5.217343314898461e-07, 'reg_lambda': 0.004241980251497593}. Best is trial 0 with value: 68119.8893549254.\n",
      "[I 2025-12-27 18:39:01,288] Trial 1 finished with value: 78157.59782578495 and parameters: {'n_estimators': 616, 'max_depth': 9, 'learning_rate': 0.13639418385240312, 'subsample': 0.8704436385180563, 'colsample_bytree': 0.8386242659438667, 'min_child_weight': 8, 'gamma': 3.6773880847974203, 'reg_alpha': 0.0016890030184496202, 'reg_lambda': 0.12361430325071071}. Best is trial 0 with value: 68119.8893549254.\n",
      "[I 2025-12-27 18:41:59,769] Trial 2 finished with value: 74878.46152716907 and parameters: {'n_estimators': 611, 'max_depth': 5, 'learning_rate': 0.04209019325812653, 'subsample': 0.5896610129840949, 'colsample_bytree': 0.9234285183131384, 'min_child_weight': 9, 'gamma': 0.989861421863022, 'reg_alpha': 0.517388177018301, 'reg_lambda': 3.3568991840301513e-07}. Best is trial 0 with value: 68119.8893549254.\n",
      "[I 2025-12-27 18:49:47,143] Trial 3 finished with value: 71048.1554985419 and parameters: {'n_estimators': 775, 'max_depth': 9, 'learning_rate': 0.018888824404130488, 'subsample': 0.5132886268918224, 'colsample_bytree': 0.9332232323981552, 'min_child_weight': 9, 'gamma': 2.1558934106149605, 'reg_alpha': 1.7662698259313365e-07, 'reg_lambda': 8.595120889721657e-08}. Best is trial 0 with value: 68119.8893549254.\n",
      "[I 2025-12-27 18:54:52,311] Trial 4 finished with value: 71480.28293227893 and parameters: {'n_estimators': 536, 'max_depth': 9, 'learning_rate': 0.030622708691428167, 'subsample': 0.557577010956144, 'colsample_bytree': 0.929201110868962, 'min_child_weight': 9, 'gamma': 2.7820361357175867, 'reg_alpha': 4.715270457311161, 'reg_lambda': 6.821661467297577e-05}. Best is trial 0 with value: 68119.8893549254.\n",
      "[I 2025-12-27 18:59:09,041] Trial 5 finished with value: 73175.12390038664 and parameters: {'n_estimators': 904, 'max_depth': 5, 'learning_rate': 0.040721102369256384, 'subsample': 0.8432359986321996, 'colsample_bytree': 0.893153346888147, 'min_child_weight': 7, 'gamma': 2.2585787587169075, 'reg_alpha': 1.3135208358040829, 'reg_lambda': 0.09959924762031297}. Best is trial 0 with value: 68119.8893549254.\n",
      "[I 2025-12-27 19:00:39,423] Trial 6 finished with value: 81325.06780158717 and parameters: {'n_estimators': 447, 'max_depth': 3, 'learning_rate': 0.060284576746480176, 'subsample': 0.8733991774813995, 'colsample_bytree': 0.7982808374856021, 'min_child_weight': 9, 'gamma': 4.647859308522365, 'reg_alpha': 3.9732018359904326e-06, 'reg_lambda': 4.406207958774106e-06}. Best is trial 0 with value: 68119.8893549254.\n",
      "[I 2025-12-27 19:08:36,566] Trial 7 finished with value: 70699.29115709424 and parameters: {'n_estimators': 690, 'max_depth': 10, 'learning_rate': 0.019382266356671517, 'subsample': 0.743699598242282, 'colsample_bytree': 0.7729545158789458, 'min_child_weight': 3, 'gamma': 0.9040009875173066, 'reg_alpha': 1.3652719337060571e-07, 'reg_lambda': 5.734933472334611e-07}. Best is trial 0 with value: 68119.8893549254.\n",
      "[I 2025-12-27 19:10:16,124] Trial 8 finished with value: 93590.88366945085 and parameters: {'n_estimators': 343, 'max_depth': 4, 'learning_rate': 0.010318512263118211, 'subsample': 0.5804584317856948, 'colsample_bytree': 0.8283485052734089, 'min_child_weight': 6, 'gamma': 2.35804662288304, 'reg_alpha': 0.009887739515765754, 'reg_lambda': 0.5109817832966241}. Best is trial 0 with value: 68119.8893549254.\n",
      "[I 2025-12-27 19:16:11,946] Trial 9 finished with value: 71961.5076905699 and parameters: {'n_estimators': 926, 'max_depth': 7, 'learning_rate': 0.016102119498883502, 'subsample': 0.8493639694407676, 'colsample_bytree': 0.701459349165976, 'min_child_weight': 1, 'gamma': 4.012362374332453, 'reg_alpha': 2.695742622610192e-07, 'reg_lambda': 3.4923044036579024e-07}. Best is trial 0 with value: 68119.8893549254.\n",
      "[I 2025-12-27 19:17:58,396] Trial 10 finished with value: 74754.04519733386 and parameters: {'n_estimators': 233, 'max_depth': 7, 'learning_rate': 0.26939255002059204, 'subsample': 0.9991792330407385, 'colsample_bytree': 0.5580858702774736, 'min_child_weight': 4, 'gamma': 0.18772811826772307, 'reg_alpha': 2.31128707546299e-05, 'reg_lambda': 0.002504378208706267}. Best is trial 0 with value: 68119.8893549254.\n",
      "[I 2025-12-27 19:26:17,517] Trial 11 finished with value: 73889.20301915746 and parameters: {'n_estimators': 745, 'max_depth': 10, 'learning_rate': 0.08455476304534532, 'subsample': 0.6974478057649357, 'colsample_bytree': 0.669344635748231, 'min_child_weight': 3, 'gamma': 1.2643196937178909, 'reg_alpha': 1.0718664739159414e-08, 'reg_lambda': 0.0017965218508149959}. Best is trial 0 with value: 68119.8893549254.\n",
      "[I 2025-12-27 19:28:09,536] Trial 12 finished with value: 68205.23231192662 and parameters: {'n_estimators': 243, 'max_depth': 8, 'learning_rate': 0.09781194916641187, 'subsample': 0.7163469952333074, 'colsample_bytree': 0.5536867612473556, 'min_child_weight': 4, 'gamma': 3.139996304637234, 'reg_alpha': 1.0966083523022813e-08, 'reg_lambda': 5.07404780555518e-05}. Best is trial 0 with value: 68119.8893549254.\n",
      "[I 2025-12-27 19:29:58,481] Trial 13 finished with value: 69296.93904623645 and parameters: {'n_estimators': 214, 'max_depth': 8, 'learning_rate': 0.11675284104544402, 'subsample': 0.9706502795032584, 'colsample_bytree': 0.5204524480532574, 'min_child_weight': 5, 'gamma': 3.331850667828341, 'reg_alpha': 1.3330575302912593e-08, 'reg_lambda': 0.00022134792505345207}. Best is trial 0 with value: 68119.8893549254.\n",
      "[I 2025-12-27 19:32:05,023] Trial 14 finished with value: 70975.94127381552 and parameters: {'n_estimators': 362, 'max_depth': 6, 'learning_rate': 0.21218439142238993, 'subsample': 0.6799777677679608, 'colsample_bytree': 0.6082252650555936, 'min_child_weight': 1, 'gamma': 4.898479439458728, 'reg_alpha': 1.0684054688024318e-05, 'reg_lambda': 4.8844233495229465}. Best is trial 0 with value: 68119.8893549254.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'n_estimators': 236, 'max_depth': 8, 'learning_rate': 0.057427200730873144, 'subsample': 0.9665654781256106, 'colsample_bytree': 0.6357966360557227, 'min_child_weight': 4, 'gamma': 3.393559749900545, 'reg_alpha': 5.217343314898461e-07, 'reg_lambda': 0.004241980251497593}\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# 4. Run Optuna study with MLflow\n",
    "# ==============================================\n",
    "# Force MLflow to always use the root project mlruns folder\n",
    "mlrun_dir = os.path.join(home_dir, \"mlruns\")\n",
    "mlflow.set_tracking_uri(mlrun_dir)\n",
    "mlflow.set_experiment(\"xgboost_optuna_housing\")\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=15)\n",
    "\n",
    "print(\"Best params:\", study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21b8c223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final tuned model performance:\n",
      "MAE: 32242.70747991763\n",
      "RMSE: 70579.9689058883\n",
      "R²: 0.961503348407537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/27 19:56:50 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmplprw461u/model, flavor: xgboost). Fall back to return ['xgboost==3.0.4']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/12/27 19:56:50 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# 5. Train final model with best params and log to MLflow\n",
    "# ==============================================\n",
    "best_params = study.best_trial.params\n",
    "best_model = XGBRegressor(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_model.predict(X_eval)\n",
    "\n",
    "mae = mean_absolute_error(y_eval, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_eval, y_pred))\n",
    "r2 = r2_score(y_eval, y_pred)\n",
    "\n",
    "print(\"Final tuned model performance:\")\n",
    "print(\"MAE:\", mae)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R²:\", r2)\n",
    "\n",
    "# Log final model\n",
    "# Add this line right before your mlflow.start_run()\n",
    "best_model._estimator_type = \"regressor\"\n",
    "with mlflow.start_run(run_name=\"best_xgboost_model\"):\n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.log_metrics({\"rmse\": rmse, \"mae\": mae, \"r2\": r2})\n",
    "    mlflow.xgboost.log_model(best_model, name=\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1c1be9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-regpipeline-endtoend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
